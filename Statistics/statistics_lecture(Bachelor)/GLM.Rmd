---
title: "통계학특강"
author: "강종경"
header-includes: \usepackage{setspace}\doublespacing
output:
  pdf_document:
    latex_engine: xelatex
    extra_dependencies: kotex
    keep_tex: yes
  word_document: default
  html_document:
    df_print: paged
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.11.2
  kernelspec:
    display_name: R
    language: R
    name: ir
mainfont: NanumGothic
editor_options:
  markdown:
    wrap: sentence
fontsize: 12pt
---

```{=tex}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
```
# 일반화 선형 모형 (Generalized Linear Model)

## 일반화선형모형이란?

선형 회귀 모형(linear regression model)에서 반응변수 $y$는 다음과 같이 설명변수들($\mathbf{x}$)의 선형결합($\mathbf{x}^\top\boldsymbol{\beta}$)에 정규분포를 따르는 오차가 붙여지는 것으로 됩니다.
$$
Y = \mathbf{x}^\top\boldsymbol{\beta}+\epsilon, \epsilon \sim N(0, \sigma^2)
$$ 이는 다음과 같이 다시 표현할 수 있습니다.

$$
Y|\mathbf{X}\sim N(\mathbf{x}^\top\boldsymbol{\beta}, \sigma^2)
$$

따라서 선형 회귀 모형에서는 정규분포를 따르는 (혹은 그에 근사할 수 있는) 반응변수를 고려합니다.
그런데 실제로는 반응변수가 이산형인 경우가 있고, 연속형이더라도 비음(nonnegative)인 경우도 있습니다.
이런 반응변수에 대해 일차적으로 생각해볼 수 있는 대표적인 모형이 일반화선형모형(generalized linear model; GLM)입니다.

GLM에서 우리가 관심있는 반응변수 $y$가 지수족(exponential family)에 속하는 분포로부터 생성되었다고 가정합니다.

### 지수족(exponential family)

지수족은 다음과 같은 형태의 확률 밀도 함수(또는 확률 질량 함수)를 가지는 확률 분포의 집합입니다.
$$
f(y|\theta)=h(y)\exp[\sum_{i=1}^{s}\eta_i(\boldsymbol{\theta})T_i(y)-A(\boldsymbol{\theta})]
$$

-   $(T_1(y), \dots, T_s(y)$: $(\eta_i(\boldsymbol{\theta}), \dots, \eta_s(\boldsymbol{\theta}))$ 에대한 결합 충분통계량
-   $\eta$ : 자연모수
-   $A(\eta) = \log\left(\int_X h(y)\exp\left(\eta\cdot T(y)\right)dy \right)$: 로그 정규화 요소
-   $k(y)= h(y)\exp\left(\eta\cdot T(y)\right)$: 확률 분포의 커널 함수
-   $T(y)$의 적률생성함수(moment generating function):

$$
M_T(t)=E\left[\exp\left(t^\top T(y)\right)\right]=\int_X h(y)\exp\left[(\eta+t)^\top T(y)-A(\eta)\right]dy=\exp\left[A(\eta+t)-A(\eta)\right]
$$

-   $K(t|\eta)= A(\eta+t)-A(\eta)$: cumulant 생성함수 $(\log E\left[\exp(tY)\right])$
    -   $K(t)=\sum_{n=1}^{\infty}\kappa_i\frac{t^n}{n!}$, $\kappa_i=K^{(n)}(0)$.
    -   $\kappa_1=E(T(Y))$, $\kappa_2=V(T(Y))$
-   정규분포(normal distribution) $Y \sim N(\mu, \sigma^2)$
    -   $h(y)= \frac{1}{\sqrt{2\pi}}$
    -   $T_1(y)=y, T_2(y)=y^2$
    -   $A(\mu, \sigma^2)=\frac{\mu^2}{2\sigma^2}+\log|\sigma|$
    -   $\eta_1=\frac{\mu}{\sigma^2}, \eta_2=-\frac{1}{2\sigma^2}$
    -   $\mu= -\frac{\eta_1}{2\eta_2}$, $\sigma^2 = -\frac{1}{2\eta_2}$
    -   $A(\eta_1, \eta_2) = -\frac{\eta_1^2}{4\eta_2}-\frac{1}{2}\log(-2\eta_2)$
-   이항분포(binomial distribution) $Y \sim B(n,p)$
    -   $f(y)=\binom{n}{y}p^{y}(1-p)^{n-y}=\binom{n}{y}\exp\left[y\log\left(\frac{p}{1-p}\right)+n\log(1-p)\right]$
    -   $\eta(p)=\log\frac{p}{1-p}$ :(로짓(logit)함수)
    -   $p=\frac{1}{1+\exp^{-\eta}}=\frac{e^\eta}{1+e^{\eta}}$ : 로지스틱(logistic) 함수
    -   $A(\eta)=n\log(1+e^\eta)$
-   포아송분포(Poisson distribution) $Y \sim Pois(\lambda)$
    -   $f(y)=\frac{\lambda^y}{y!}\exp(-\lambda)=\frac{1}{y!}\exp\left[y\log\lambda-\lambda\right]$
    -   $\eta(\lambda)=\log\lambda$
    -   $\lambda = e^\eta$
    -   $A(\eta) = e^\eta$
-   감마분포(Gamma distribution) $Y \sim Gamma(\alpha,\gamma)$
    -   $f(y)=\frac{y^{\alpha-1}\exp^{-\gamma y}\gamma^{\alpha}}{\Gamma(\alpha)}=\exp\left[(\alpha-1)\log y -\gamma y +\alpha \log\gamma-\log\Gamma(\alpha)\right]$\
    -   $\Gamma(\alpha)=\int_{0}^{\infty}x^{\alpha-1}e^{-x}dx$
    -   $\eta_1=\alpha-1, \eta_2=-\gamma$
    -   $\alpha = \eta+1, \gamma = -\eta_2$
    -   $h(y)=1$
    -   $T_1(y)=\log y, T_2(y)=y$
    -   $A(\alpha, \gamma)= \log\Gamma(\alpha)-\alpha\log\gamma$
    -   $A(\eta_1, \eta_2) = \log\Gamma(\eta_1+1)-(\eta_1+1)\log(-\eta_2)$

그리고 $Y$의 평균 $\mu$는 $p$차원 설명변수 $\mathbf{x}=(x_1, x_2, \dots, x_p)^\top$와 다음과 같은 관계가 있다고 가정합니다.

```{=tex}
\begin{equation}\tag{1}
E(Y|\mathbf{x})=\mu=g^{-1}(\mathbf{x}^\top\boldsymbol{\beta})=g^{-1}(\eta)
\end{equation}
```
(1)에서 $Y$의 평균 $\mu$를 적당한 함수를 이용하여 변환하면 우리가 알고자 하는 모수$\boldsymbol{\beta}$의 선형결합인 $\eta=\mathbf{x}^\top\boldsymbol{\beta}$의 형태로 나타남을 알 수 있습니다.
즉, $g(\mu)=\eta=\mathbf{x}^\top\boldsymbol{\beta}$가 됩니다.
이러한 함수 $g$를 연결 함수(link function)라고 합니다.

이와 같이 GLM은 세 개의 특징으로 구성되어 집니다.

1.  지수족에 해당하는 확률분포
2.  선형 예측자 $\eta = \mathbf{x}^\top\boldsymbol{\beta}$
3.  연결 함수 $g: E(Y|\mathbf{x})=\mu = g^{-1}(\eta)$

## 연결 함수

연결함수는 선형 예측자 $\eta = \mathbf{x}^\top\boldsymbol{\beta}$와 분포의 평균을 연결해주는 역할을 합니다.
선형 예측자와 분포의 평균$\mu$을 연결해주는 함수에는 여러가지가 있을 수 있겠지만, 일반적으로는 분포의 평균 $\mu$와 자연모수 $\eta$를 $g(\mu)=\eta$와 같이 연결하는데, 이를 정준(canonical) 연결 함수라고 합니다.

-   정규분포 : $\eta = g(\mu)$
-   이항분포 : $\eta = \log\frac{\mu}{n-\mu}$
-   포아송분포 : $\eta = \log\mu$
-   감마분포 : $\eta = -\frac{1}{\mu}$

정준연결함수 $g(\mu)=\eta = \mathbf{X}\boldsymbol{\beta}$을 이용하면 $\mathbf{X}^\top T(\mathbf{Y})$는 $\boldsymbol{\beta}$에 대한 충분통계량이 됩니다.

## GLM의 적합

$n$개의 독립적인 관측치가 있다면, 가능도 함수는 다음과 같은 형태를 갖습니다.

$$
L(\boldsymbol{\beta})=\prod_{i=1}^{n}f_{\eta_i}(y_i)
$$

각 관측치는 공통 벡터$\boldsymbol{\beta}$에 따라 달라지는 고유한 정준 모수를 가질 수 있기 때문에 정준 모수에도 아래첨자 $i$를 표기하였습니다.
로그 가능도 함수는 다음과 같습니다.

$$
l(\boldsymbol{\beta})=\log L(\boldsymbol{\beta})=\sum_{i=1}^{n}\left[T(y_i)\eta_i-A_i(\eta_i)+\log(h(y_i))\right]
$$ 여기서 $\log(h(y_i))$는 $\boldsymbol{\beta}$에 의존하지 않기 때문에 $\boldsymbol{\beta}$의 추정에 영향을 주지 않습니다.
최대 가능도 추정량 $\boldsymbol{\beta}$는 다음과 같이 정의됩니다.

$$
\hat{\boldsymbol{\beta}}=\text{argmax}_{\boldsymbol{\beta}}l(\boldsymbol{\beta})
$$

정규분포의 경우 $\hat{\boldsymbol{\beta}}$에 대한 닫힌 해가 존재하지만, 다른 지수족 반응변수에 대해서는 닫힌 해가 존재하지 않으므로, 수치적으로 반복함을 통해 $\hat{\boldsymbol{\beta}}$를 추정합니다.
대표본에서 최대가능도 추정량 $\hat{\boldsymbol{\beta}}$는 점근적으로 다변량 정규분포를 따릅니다.
\begin{equation}\tag{3}
\hat{\boldsymbol{\beta}}\approx N(\boldsymbol{\beta}, I^{-1})
\end{equation} 여기서 $I$는 최대우도 추정에 있어서의 Fisher 정보 행렬입니다.

## 가능도비 검정(likelihood ratio test)

다음과 같이 서로 내포된 두 모형 $M_0$과 $M_1$ $(M_0 \subset M_1)$ 에 관한 검정 문제를 생각해 봅시다.
$$
H_0: g(\mu_i)=\mathbf{x}_{i0}^\top\boldsymbol{\beta}_0 \quad vs. \quad H_1: g(\mu_i)=\mathbf{x}_{i1}^\top\boldsymbol{\beta}_1
$$ 여기서 $\mathbf{x}_{i0}\subset \mathbf{x}_{i1}$ 입니다.
두 모형 $M_0$과 $M_1$에서의 모수의 수를 각각 $p_0$, $p_1$이라고 합시다($p_0<p_1$).
그러면 가능도비 검정통계량은 다음과 같습니다.
$$
2\left[l(\hat{\boldsymbol{\beta}}_1)-l(\hat{\boldsymbol{\beta}}_0)\right] \approx \chi_{p_1-p_0}^2
$$

## 이탈도(deviance)

GLM의 이탈도 개념은 반응변수가 정규분포를 따를 때의 선형 회귀 모형에서 사용되는 잔차 제곱합과 유사하게 적합성 결여를 정량화하는 데 사용됩니다.
적합 모형의 이탈도는 다음과 같이 정의 됩니다.

$$
D=2\left[l(\hat{\boldsymbol{\beta}}_{\max}-l(\hat{\boldsymbol{\beta}})\right]\phi
$$ 여기서 $l(\hat{\boldsymbol{\beta}}_{\max})$는 포화모형($n$개의 모수가 있는 모형)에서의 로그 최대가능도이며, $l(\hat{\boldsymbol{\beta}})$는 관심있는 모형에서의 로그 최대가능도입니다.
참고로 포화모형에서는 $\hat{\mu}_i=y_i$입니다.
조정된 이탈도(scaled deviance)는 이탈도를 분산모수 $\phi$로 나눠준 값입니다.
$$
D^*=D/\phi
$$ 조정된 이탈도는 이탈도를 분산에 영향받지 않는 값으로 만들어줍니다.
그러면 가능도비검정 통계량은 다음과 같이 다시 쓸 수 있습니다.
$$
D_0^*-D_1^* \approx \chi_{p_1-p_0}^2
$$ 여기서 $D_0^*$와 $D_1^*$는 각각 모형 $M_0$과 $M_1$의 조정된 이탈도입니다.

조정된 이탈도 또는 가능도비 검정에서는 분산모수 $\phi$를 필요로 하지만, 어떤 경우에서는 이 값이 알려져 있지 않을 수 있습니다.
$$
D_0^*-D_1^* \approx \chi_{p_1-p_0}^2 \qquad \text{그리고} D_1^* \approx \chi_{n-p_1}^2
$$ 이므로, 다음과 같이 $F$ 통계량으로 근사적인 검정을 수행할 수 있습니다.
$$
F=\frac{(D_0-D_1)/(p_1-p_0)}{D_1/(n-p_1)} \approx F_{p_1-p_0, n-p_1}
$$ $F$통계량에서는 조정되지 않은 이탈도(unscaled deviance)를 사용하였는데, 이는 분자와 분모에 공통적으로 존재하는 $\phi$가 약분되어 식에서 사라졌기 때문입니다.

## 모형 비교

Akaike 정보 기준(Akaike's Information Criterion; AIC)과 베이즈 정보 기준(Bayesian Information Criterion; BIC) 등은 내포되지 않은 모형의 비교에 이용될 수 있습니다.
$$
AIC=-2l(\hat{\boldsymbol{\beta}})+2p \qquad BIC=-2l(\hat{\boldsymbol{\beta}})+\log(n)p
$$ AIC 또는 BIC가 작을수록 더 선호되는 모형입니다.

## 로지스틱 회귀

$Y$가 이항변수인 경우에 로지스틱 회귀를 이용합니다.
$Y$가 0과 1로 코딩되어 있고, $Y$의 값에 영향을 줄 수 있는 $p$개의 공변량 $x_1, \dots, x_p$가 있는 경우, 로지스틱 회귀는 $Y=1$대 0의 로그 오즈(log odds)를 $x_1, \dots, x_p$의 선형결합으로 표현할 수 있음을 가정합니다.

$$
\log\frac{P(Y=1|x_1, \dots, x_p)}{P(Y=0|x_1, \dots, x_p)}=\log\frac{p}{1-p}=\beta_0+\beta_1x_1+\dots \beta_px_p
$$ 이는 다음과 같은 로지스틱 모형의 가정과 같은 의미를 지닙니다.

```{=tex}
\begin{equation}\tag{4}
Y|\mathbf{x}\sim B\left(1, p=\frac{\exp(\mathbf{x}^\top\boldsymbol{\beta})}{1+\exp(\mathbf{x}^\top\boldsymbol{\beta})}\right)
\end{equation}
```
### 오즈(odds)

이항 확률 변수 $Y$의 오즈(승산)는 다음과 같이 정의됩니다.
$$
\frac{P(Y=1)}{P(Y=0)}
$$ 예를들어 '성공률이 66% 이다'라는 문장이 있다면, 이는 '성공의 오즈가 2:1이다' 라는 문장과 동일한 의미 입니다.
'내기'에 빗대서 생각해본다면, A와 B의 대결에서 A가 이길 확률이 66%로 예측된다면, A가 이겼을 때의 배당과 B가 이겼을 때의 배당 비는 1:2가 됩니다.
확률이 0과 1사이의 값을 갖는 반면, 오즈는 0 ($P(Y=1)=0$) 부터 무한대 ($P(Y=1)=1$)까지의 값을 갖습니다.

### 오즈비(odds ratio)

오즈비는 두 이항 확률변수 $Y_1$, $Y_2$의 오즈의 비율로 정의됩니다.

$$
OR(Y_1,Y_2):= \frac{P(Y_1=1)/P(Y_1=0)}{P(Y_2=1)/P(Y_2=0)}
$$ 오즈비(OR)는 두 그룹의 확률을 비교하지만 확률 척도가 아니라 오즈 척도로 비교합니다.
또한 OR은 두 베르누이 분포 사이의 거리를 측정한 값이라고 생각할 수도 있습니다.
OR은 두 확률의 비교에 있어서 $P(Y_1=1)-P(Y_2=1)$와 같은 다른 후보 거리 측도보다 수학적 특성이 우수합니다.

(4)번식과 같은 로지스틱 회귀모형에서 두 확률변수 $Y|\mathbf{x}=1$과 $Y|\mathbf{x}=0$의 오즈비는 다음과 같습니다.

$$
OR(Y|\mathbf{x}=1,Y|\mathbf{x}=0)=\frac{P(Y=1|\mathbf{x}=1)/P(Y=0|\mathbf{x}=1)}{P(Y=1|\mathbf{x}=0)/P(Y=0|\mathbf{x}=0)}=e^\beta_1
$$ 즉 로지스틱 회귀분석에서 $\beta$는 설명변수 $x_1$의 단위 증가로 인한 로그 오즈비로 해석할 수 있습니다.

### PlantGrowth 자료

`PlantGrowth`자료는 식물의 무게와 세가지 조건(통제, 처리1, 처리2)이 기록되어 있습니다.

```{r chunk1}
head(PlantGrowth)
```

`cut` 함수를 사용하여 `weight`변수를 `Light`와 `Heavy` 로 이항 반응 변수(로지스틱 회귀 분석을 수행 중이므로 두 클래스 응답이 필요함)를 만들어 보겠습니다.
일반적으로 연속형 변수를 이항변수로 변환하면 정보가 손실되므로 일반적인 회귀분석이 보다 나은 분석이 될 수 있습니다만, 여기서는 단순 로지스틱 회귀의 예시로서 이해해주기 바랍니다.

```{r chunk2}
weight.factor<- cut(PlantGrowth$weight, 2, labels=c('Light', 'Heavy')) 
plot(table(PlantGrowth$group,weight.factor))
```

자료를 `attach`하여 다음과 같이 진행할 수도 있습니다.

```{r chunk3}
attach(PlantGrowth)
weight.factor<- cut(weight, 2, labels=c('Light', 'Heavy')) 
plot(table(group, weight.factor))
```

로지스틱 회귀분석은 `glm`함수에 `family=binomial`옵션을 추가하여 수행할 수 있습니다.

```{r chunk4}
glm.1<- glm(weight.factor~group, data=PlantGrowth, family=binomial)
summary(glm.1)

```

`lm`에서와 마찬가지로 회귀계수에 대한 표를 얻지만, "링크 척도"에서는 (로그) 오즈비로 해석해야 합니다.
여기서의 $p$-값은 (3)에서 보인것과 같이 점근적인 상황하에서 계산된 값이므로 표본의 크기가 작을 때는 정확하지 않을 수 있습니다.
`lm`에서와는 다르게 잔차(residual) 대신 이탈도(deviance)가 보고된 것을 알 수 있습니다.

이제 `group`변수 즉, 처리 효과가 있는지에 대해 분산분석을 수행해봅시다.

```{r chunk5}
anova(glm.1, test='LRT')
```

여기서는 가능도비 검정을 수행하였습니다.
다른 검정 방법들에 대한 정보는 `?anova.glm`을 통해 확인하기 바랍니다.
여기서의 검정결과도 대표본에서의 근사 검정방법임을 참고하세요.
`group`요인이 유의하게 나왔으므로, 식물 무게의 분포는 주어진 처리에 따라 달라진다고 할 수 있습니다.

```{r chunk6}
contrasts(weight.factor)
```

이 실험에서는 무거운 식물(`Heavy`)이 1로, 가벼운 식물(`Light`)가 0으로 코딩되었습니다.
이제 각 처리에서 식물의 무게가 무겁게(`Heavy`) 나올 확률을 예측해봅시다.

```{r chunk7}
pred_prob<-predict(glm.1, type='response')
names(pred_prob)<-PlantGrowth$group
pred_prob
```

`type='link'`로 할 경우, 로그 오즈 스케일의 예측결과를 보여줍니다.

선형 회귀에서와 마찬가지로 진단을 위한 간단한 그림들을 확인해볼 수 있습니다.

```{r chunk8}
par(mfrow = c(2,2))
plot(glm.1)
```

### Pima.te 자료

다음으로 `MASS` 패키지에 있는 `Pima.te`자료를 분석해봅시다.

```{r chunk9}
data('Pima.te', package='MASS') # Loads data
head(Pima.te)
```

여기서는 `type`을 반응변수로 하여 여러 설명변수들 가운데 가장 좋은 모형을 찾아보겠습니다.
`step`함수는 단계별회귀(stepwise regression)을 수행하여, 연속적으로 유의하지 않은 변수들을 제거합니다.
`step`함수는 수행결과로서 체크한 각 모델과 각 단계에서 제거하기로 결정한 변수를 보고하며, 최종 결과물로 선택된 변수들로 만든 모형을 제공합니다.

```{r chunk10}
glm.2<- step(glm(type~., data=Pima.te, family=binomial))
summary(glm.2)
```

## 포아송 회귀

포아송 회귀는 종속변수 $Y$가 도수(count)인 경우에 적용되는 일반화 선형모델로 반응변수의 조건부 분포가 다음과 같은 포아송 분포를 따른다고 가정합니다.
$$
Y|\mathbf{x}\sim Poisson(\lambda(\mathbf{x})=\exp(\mathbf{x}^\top\boldsymbol{\beta}))
$$ 포아송 회귀는 로그 연결함수$g(\mu)=log(\eta)$를 사용합니다.
$x_1=1$인 그룹과 $x_1=0$인 그룹에서의 연결함수 값을 살펴봅시다.

$$
\lambda(x_1=1)=\exp(\beta_0+\beta_1)=\exp(\beta_0)\exp(\beta_1)=\lambda(x_1=0)\exp(\beta)
$$

로그 연결 함수는 $x$의 한단위 변화할 때 $Y$의 평균이 $\exp(\boldsymbol{\beta})$의 만큼 변화함을 알려줍니다.

## 예제

어떤 병의 발병 이후 일자별 감염된 고등학생의 수에 관한 다음 자료를 살펴봅시다.

```{r chunk11}
cases <-  
structure(list(Days = c(1L, 2L, 3L, 3L, 4L, 4L, 4L, 6L, 7L, 8L, 
8L, 8L, 8L, 12L, 14L, 15L, 17L, 17L, 17L, 18L, 19L, 19L, 20L, 
23L, 23L, 23L, 24L, 24L, 25L, 26L, 27L, 28L, 29L, 34L, 36L, 36L, 
42L, 42L, 43L, 43L, 44L, 44L, 44L, 44L, 45L, 46L, 48L, 48L, 49L, 
49L, 53L, 53L, 53L, 54L, 55L, 56L, 56L, 58L, 60L, 63L, 65L, 67L, 
67L, 68L, 71L, 71L, 72L, 72L, 72L, 73L, 74L, 74L, 74L, 75L, 75L, 
80L, 81L, 81L, 81L, 81L, 88L, 88L, 90L, 93L, 93L, 94L, 95L, 95L, 
95L, 96L, 96L, 97L, 98L, 100L, 101L, 102L, 103L, 104L, 105L, 
106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L), 
    Students = c(6L, 8L, 12L, 9L, 3L, 3L, 11L, 5L, 7L, 3L, 8L, 
    4L, 6L, 8L, 3L, 6L, 3L, 2L, 2L, 6L, 3L, 7L, 7L, 2L, 2L, 8L, 
    3L, 6L, 5L, 7L, 6L, 4L, 4L, 3L, 3L, 5L, 3L, 3L, 3L, 5L, 3L, 
    5L, 6L, 3L, 3L, 3L, 3L, 2L, 3L, 1L, 3L, 3L, 5L, 4L, 4L, 3L, 
    5L, 4L, 3L, 5L, 3L, 4L, 2L, 3L, 3L, 1L, 3L, 2L, 5L, 4L, 3L, 
    0L, 3L, 3L, 4L, 0L, 3L, 3L, 4L, 0L, 2L, 2L, 1L, 1L, 2L, 0L, 
    2L, 1L, 1L, 0L, 0L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 0L, 0L, 
    0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L)), .Names = c("Days", "Students"
), class = "data.frame", row.names = c(NA, -109L))
head(cases)
with(cases, plot(Days, Students, xlab = "DAYS", ylab = "STUDENTS", pch = 16))

```

`with` 함수를 통해 `attach`한 효과를 줄 수 있습니다.
일자(`DAYS`)와 학생 수(`STUDENTS`)의 산점도는 일자가 지남에 따라 발병학생수가 감소하는 패턴을 보여주고 있습니다.

```{r chunk12}
glm.3 <- glm(Students ~ Days, data= cases, family = poisson)
summary(glm.3)
```

하루가 지날 때마다 평균 사건 발생도가 $e^{\beta_1}=0.98$배가 됨을 즉, 하루에 2%씩 줄어듬을 알 수 있습니다.

마지막으로 발병수와 로그 발병수에 대한 예측선을 그려봅시다.

```{r chunk13}
plot(Students~Days, data=cases, xlab = "Days", ylab = "Students")
lines(cases$Days, glm.3$fitted.values)
```

```{r chunk14}
plot(log(Students)~Days, data=cases, xlab = "Days", ylab = "log(Students)")
lines(cases$Days, glm.3$linear.predictors)
```
